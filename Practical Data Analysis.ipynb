{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e555b440-6028-4475-b4a2-da1e631a3baf",
   "metadata": {},
   "source": [
    "# Practical Data Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69520795-412f-4f72-ab88-b88cc40c4a9c",
   "metadata": {},
   "source": [
    "## Lesson 1\n",
    "***https://www.youtube.com/watch?v=AwIxx1nbQB4&ab_channel=SandroDiasPintoVitenti***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7cc0634a-cd7a-4176-8b10-8c7f6ef9d20f",
   "metadata": {},
   "source": [
    "### Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9407ca52-e850-4f74-890d-c6689520361b",
   "metadata": {},
   "source": [
    "One could think that the main object of data analysis is a set of observations $ \\{x_i\\} $ and an existing relationship between these measurements. These assumptions are mainly a belief that there is a deeper reality besides the measurement. For us, this relation is materialized by the probability distribution $P$.\n",
    "\n",
    "The probability of a measument $x$ given an a hypothesis $\\theta$ is $$P(x|\\theta).$$ There are two main methods of working in this space.\n",
    "\n",
    "* Parametric methods: We know the probability distribuition, or at least we think so, then we can simulate a sample;\n",
    "\n",
    "* Unparametric methods: We do not know the probability distribuition, therefore, we try to discover it via our observations set.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb4eb436-ced1-408b-bad4-f5426bbb00fe",
   "metadata": {},
   "source": [
    "### Dataset description"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7e9c637-01e0-4482-a973-cf379884d025",
   "metadata": {},
   "source": [
    "We begin by describing our dataset. For instance, say we have a set observation of the position of galaxies in our sky. If we start by applying statistics to their actual position, we would be inclined to a specific probability distribution $P$. Moreover, if we decide to \"clump\" our galaxies into particular pixels, we would find a whole new distribution.\n",
    "\n",
    "Furthermore, it is maximal that we correctly describe our data statistically. Let us say we have two different distributions:\n",
    "\n",
    "$$.\\;.\\;.\\;.\\;.\\;.\\;.\\;.\\;.\\;.\\;.\\; \\{x_1\\}$$\n",
    "\n",
    "$$........... \\{x_2\\}$$\n",
    "\n",
    "If we were to calculate the mean value of both, we would get the same value $\\bar{x}$, but it is clear that these dataset are very diferent. Therefore, we must calculate other metrics."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99407251-0f8f-4300-8ce0-569646d82076",
   "metadata": {},
   "source": [
    "### Computational methods"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffecae47-bb07-4e01-99a1-08fb1072e9d9",
   "metadata": {},
   "source": [
    "We shall use computational methods to generate a sample $\\{x_i\\}^N$ and calculate the value of $P(x)$ for every generated point. The first problem we will encounter is the fact that computers are intrinsically integer finite machines. \n",
    "\n",
    "The solution to our integrity problem lies in floating-point numbers. We shall give a tuple of an integer, and the position of the point. This is the definition of ***float values***!  (づ￣ ³￣)づ\n",
    "\n",
    "Now, to solve the finiteness problem, we implement interpolation. Intead of calculating every value $P(x)$, we will use two calculated values for $(x_1;P(x_1))$ and $(x_2; P(x_2))$ to find a third without the explicit calculation $P(x_3)$. As an example, we can find the value of $P(x_3)$ via a linear interpolation \n",
    "$$ \n",
    "\\bar{P}_1(x_3) = P_1 + (P_2 - P_1)\\frac{(x_3-x_1)}{(x_2-x_1)} \\;;\\; x_1<x_3<x_2\n",
    "$$\n",
    "\n",
    "Then, our fucntion will be described by\n",
    "\n",
    "$$\n",
    "P(x) = \\left\\{\n",
    "    \\begin{array}\\\\\n",
    "        P(x_1) & \\mbox{if } \\ x = x_1 \\\\\n",
    "        \\bar{P}_1(x_3) & \\mbox{if } \\ x = x_3 \\\\\n",
    "        P(x_2) & \\mbox{if } \\ x=x_2 \\\\\n",
    "        \\vdots\n",
    "    \\end{array}\n",
    "\\right.\n",
    "$$\n",
    "\n",
    "We could use interpolation of a greater order. However, these methods are much more complex and require descriptions of the differential of $\\bar{P}(x)$  to impose continuity of the function."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2778c65-7cda-4451-aa00-7d3b4f918bb1",
   "metadata": {},
   "source": [
    "### Random varibles"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a0ef4ff-d331-46bd-802d-15f9418fafa3",
   "metadata": {},
   "source": [
    "Given a probability distribution $P(x)$, we define\n",
    "\n",
    "$$\n",
    "C(x) = \\int_a^b P(x) dx.\n",
    "$$\n",
    "\n",
    "Furthermore, let us say $x$ is a random variable, with an expected value\n",
    "\n",
    "$$\n",
    "<x> = \\int P(x) x dx.\n",
    "$$\n",
    "\n",
    "Therefore, if $x$ is a random variable, then $C(x)$ will also be a random variable. Moreover, we might ask what is the probability of $C(x)$ be equal a certain value. This will give us a probability distribuition for $C$, \n",
    "\n",
    "$$\n",
    "P(C = C_0) = \\int P(x) \\delta(C(x) - C_0(x)) dx.\n",
    "$$\n",
    "\n",
    "This integral is easy to solve. By the definition of $C(x)$, we know $\\partial_x C(x) = P(x)$. Since the probability distribution is a positive definite function, $C(x)$ is a monotonic function, i.e., $C$ is an inversible function. Now, because $C$ is inversible, the argument of the Dirac's delta function is defined on only one point $C(x_0) = C_0$. Replacing $C_0(x)$ by $C(x_0)$ on the integral, and using the fact that\n",
    "\n",
    "$$\n",
    "\\delta(f(x)) = \\frac{\\delta(x-x_0)}{\\left|\\frac{\\partial f(x_0)}{\\partial x}\\right|},\n",
    "$$\n",
    "\n",
    "we get\n",
    "\n",
    "$$\n",
    "P(C = C_0) = \\frac{P(x_0)}{\\left|\\frac{\\partial C(x_0)}{\\partial x}\\right|} = 1.\n",
    "$$\n",
    "\n",
    "This confirms that our distribution gives the equal probability for every possible value of our dataset.\n",
    "\n",
    "Now we can calculate $C(x)$ using a set $\\{x_i , C_i\\}$. Not only $C(x)$, we can also calculate $\\widetilde{X}(C)$, using the fact that $C(x)$ is inversible. We are doing all this to get a random sample. Since a computer can give an algorithm that takes a random sample from a uniform distribution, we do not need to know how to choose values for the calculation of $P(x)$. Therefore, given an uniform distribution $U(a, b) \\rightarrow \\{U_i\\}$, we can generate a random sample ${X_i} = \\widetilde{X}(U_i)$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e2f0449-a8b7-4a27-b270-01bdee5d60e6",
   "metadata": {},
   "source": [
    "### Activity 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7cf0a2a-6105-4c0f-9d79-5632dd77cf80",
   "metadata": {},
   "source": [
    "Firstly, using the Gaussian distribution\n",
    "\n",
    "$$\n",
    "P(x|\\mu, \\sigma) = \\frac{1}{\\sqrt{2\\pi}}\\frac{e^{-\\frac{\\left(x-\\mu\\right)^2}{2\\mu^2}}}{\\sigma},\n",
    "$$\n",
    "\n",
    "and\n",
    "\n",
    "$$\n",
    "C(x) \\propto Erf.\n",
    "$$\n",
    "\n",
    "Calculate the interpolated version of $P(x|\\mu, \\sigma)$ and $C(x)$, and compare them with the same functions in the library of your choice.\n",
    "\n",
    "Secondly, using a random sample generator from a uniform distribution, generate a random sample for $\\widetilde{X}(U_i)$ and plot barplot over a continuous version of the Gaussian distribution (interpolated and library given)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "381fe9e4-f6e0-4e55-a57d-d5ec307d006a",
   "metadata": {},
   "source": [
    "### Likelihood"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6237fb0e-dfa8-4dba-b384-184f4d6e0b40",
   "metadata": {},
   "source": [
    "*For further reading, see* ***https://sites.warnercnr.colostate.edu/gwhite/wp-content/uploads/sites/73/2017/04/BinomialLikelihood.pdf*** \n",
    "\n",
    "Say we have a certain event with $P$ probability of happening. With $n$ occurencies, this particular event happended $r$ times, the likelihood will be given by\n",
    "\n",
    "$$\n",
    "\\mathcal{L}(p|n, r) =\\binom{n}{r} p^r (1-p)^{n-r}.\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11e28ba1-1be6-4c83-bd20-961844081ea9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
